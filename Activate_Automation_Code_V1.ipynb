{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80792ea3-4eb7-4888-81f3-14ea1181fdfe",
   "metadata": {},
   "source": [
    "## ACTIVATE AUTOMATION CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6056dc78-9971-41a0-98cb-9863e9a62265",
   "metadata": {},
   "source": [
    "### MUST HAVE \n",
    "+ have the Level 3 Mapping in the Contribution Tab, Spends Tab, Support Tab\n",
    "+ Tabs named **Factor_Code** & **Time_Mapping** present for the Price Margin Creation\n",
    "+ **If using for Another Project, Need to make changes in code regarding the Time Mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5269f330-4b48-4ddf-b22c-b1be06fa1bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785bad1d-d32f-4b91-a04f-b883eb40e03c",
   "metadata": {},
   "source": [
    "### ACTIVATE INPUT SETUP \n",
    "+ Please enter your folder directory where you are having the Input File\n",
    "+ Specify the Input/Output file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a9a935f-3abc-4a79-a74f-cc7b1279fa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Output file found and loaded.\n"
     ]
    }
   ],
   "source": [
    "# SPECIFY HERE\n",
    "# Path should be having a r before the path \n",
    "# Ex : r\"C:/Folder1/Activate_Files\"\n",
    "start_time = time.time()\n",
    "folder = r\"C:\\Users\\Beeraboina.Rahul\\OneDrive - Ipsos\\Work\\Python Code Automation\"\n",
    "\n",
    "# SPECIFY THE NAMES \n",
    "input_file = \"MCUSC_2025_Annual_Cholula_WB_12.1.25_US.xlsx\"\n",
    "output_file = f\"Activate_DataSet_{datetime.now().strftime('%m-%d-%Y')}.xlsx\"\n",
    "\n",
    "Input_path = os.path.join(folder,input_file)\n",
    "Output_path = os.path.join(folder,output_file)\n",
    "\n",
    "# CHECKING IF AN OUTPUT FILES EXIST OR NOT\n",
    "if os.path.exists(Output_path):\n",
    "    Output = pd.read_excel(Output_path)\n",
    "    print(\"✔ Output file found and loaded.\")\n",
    "else:\n",
    "    # Create an empty file or add specific columns if needed\n",
    "    Output = pd.DataFrame()\n",
    "    # Create new Excel file\n",
    "    Output.to_excel(Output_path, index=False)\n",
    "    print(\"⚠ Output file not found. A new one has been created:\", Output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "142be316-6f35-436b-838a-1a051b76d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all sheets\n",
    "sheets = pd.read_excel(Input_path, sheet_name=None)\n",
    "\n",
    "with pd.ExcelWriter(Output_path, engine=\"openpyxl\") as writer:\n",
    "    for sheet_name, df in sheets.items():\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # TAB 1: Weekly logic\n",
    "        # -----------------------------------------\n",
    "        if sheet_name == \"Weekly\":\n",
    "\n",
    "            date_columns = df.columns[9:]\n",
    "            result = df.groupby([\"ModelKey\", \"Level 3\"], as_index=False)[date_columns].sum()\n",
    "            result.columns = result.columns.map(lambda x: x.strftime(\"%m-%d-%Y\") if hasattr(x, \"strftime\") else x)\n",
    "            result.to_excel(writer, sheet_name=\"Contribution\", index=False)\n",
    "\n",
    "        elif sheet_name == \"WeeklySupport\":\n",
    "\n",
    "            # Example: group by Category instead\n",
    "            date_columns = df.columns[3:] \n",
    "            result = df.groupby([\"Level 3\"], as_index=False).sum()\n",
    "            result.columns = result.columns.map(lambda x: x.strftime(\"%m-%d-%Y\") if hasattr(x, \"strftime\") else x)\n",
    "            result.to_excel(writer, sheet_name=\"Data\", index=False)\n",
    "\n",
    "        # -----------------------------------------\n",
    "        # TAB 3: Daily logic\n",
    "        # -----------------------------------------\n",
    "        elif sheet_name == \"WeeklySpend\":\n",
    "\n",
    "            # Example: filter + group\n",
    "            date_columns = df.columns[2:]\n",
    "            result = df.groupby(\"Level 3\", as_index=False).sum()\n",
    "            result.columns = result.columns.map(lambda x: x.strftime(\"%m-%d-%Y\") if hasattr(x, \"strftime\") else x)\n",
    "            result.to_excel(writer, sheet_name=\"WeeklySpend\", index=False)\n",
    "\n",
    "        elif sheet_name == \"Activate Mappings\":\n",
    "\n",
    "            CONCAT_MAPPING = sheets[\"Activate Mappings\"].loc[:, [\"Type\", \"Variable\", \"Variable(Level3)\", \"Decay\", \"Learn\"]]\n",
    "            Incremental = CONCAT_MAPPING.loc[CONCAT_MAPPING[\"Type\"] == \"Incremental\"].copy()\n",
    "            Incremental.loc[:, \"Transformation Formula\"] = (\"APL([\" + Incremental[\"Variable\"].astype(str)+ \"],0,\"+ Incremental[\"Decay\"].astype(str)+ \",\"+ Incremental[\"Learn\"].astype(str)+ \",0)\")\n",
    "            Incremental_Level3_Unique = Incremental.drop_duplicates(subset=[\"Variable(Level3)\"])\n",
    "            Incremental_Level3_Unique.to_excel(writer,sheet_name=\"Variable_Sheet\",index=False)\n",
    "\n",
    "        elif sheet_name == \"Factors\":\n",
    "\n",
    "            # PROJECTION FACTOR SHEET CREATION\n",
    "            metric_df = sheets[\"Factor_Code\"]\n",
    "    \n",
    "            Model_List = sheets[\"Factor_Code\"].ModelKey.unique().tolist()\n",
    "            KPI = [\"ProjUnits\",\"Profit\",\"Revenue\"]\n",
    "\n",
    "\n",
    "            # In the below code, if you are using this code for antoher project, Make changes in the formatting string below.\n",
    "            # It appends the Cholula for each and every model of the project. It is basically a Cartesian Product of the KPIs and the Model.\n",
    "            PMCombo= pd.DataFrame([(f\"Cholula {m.replace('_', ' ')}\", k) for m in Model_List for k in KPI],columns=[\"Model\", \"KPI\"])\n",
    "            \n",
    "            Time_Mapping = sheets[\"Time Mapping\"]\n",
    "            Time_Mapping[\"Date\"] = pd.to_datetime(Time_Mapping[\"Date\"]).dt.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "            Date_As_Cols = pd.DataFrame(columns=Time_Mapping.iloc[:,1])\n",
    "            ModelPriceMargin = pd.concat([PMCombo,Date_As_Cols],axis=1)\n",
    "\n",
    "            # MAKE CHANGES HERE\n",
    "            # When using for a new project, need to make changes to the Time Mapping in it as CY52, LY52 & TYA52 are\n",
    "            # specific for Cholula Project.\n",
    "            Projection_df = metric_df.loc[metric_df[\"Metric\"] == \"PROJECTION\",[\"ModelKey\",\"CY 52\",\"LY52\",\"TYA52\"]]\n",
    "\n",
    "            Projection_long = Projection_df.melt(id_vars=\"ModelKey\",var_name=\"Mapping\",value_name=\"Value\")\n",
    "\n",
    "            Projection_long = Projection_long.merge(Time_Mapping,on=\"Mapping\",how=\"left\")\n",
    "            date_order = Time_Mapping[\"Date\"].drop_duplicates().tolist()\n",
    "            \n",
    "            Projection_pivot = Projection_long.pivot(index=\"ModelKey\",columns=\"Date\",values=\"Value\").reset_index()\n",
    "            \n",
    "            Projection_pivot = Projection_pivot[[\"ModelKey\"] + date_order]\n",
    "            \n",
    "            Projection_pivot[\"Model\"] = \"Cholula \" + Projection_pivot[\"ModelKey\"].str.replace(\"_\",\" \") \n",
    "\n",
    "            Final_ModelPriceMargin = ModelPriceMargin.merge(Projection_pivot,on=\"Model\",how=\"left\")\n",
    "            Final_ModelPriceMargin = Final_ModelPriceMargin.loc[:,~Final_ModelPriceMargin.columns.str.endswith(\"_x\")]\n",
    "            Final_ModelPriceMargin.columns = Final_ModelPriceMargin.columns.str.replace('_y$',\"\",regex=True)\n",
    "            Final_ModelPriceMargin = Final_ModelPriceMargin.drop(columns=[\"ModelKey\"])\n",
    "            Final_ModelPriceMargin.to_excel(writer,sheet_name=\"ProjectionFactor\",index=False)\n",
    "\n",
    "            # MODEL_PRICE_MARGIN CREATION\n",
    "            DF_model = pd.DataFrame({\"Model\":Model_List})\n",
    "            Time_Mapping[\"key\"] = 1\n",
    "            DF_model[\"key\"] = 1\n",
    "            MPM = DF_model.merge(Time_Mapping,on=\"key\").drop(columns=\"key\")\n",
    "            MPM[\"Model\"] = \"Cholula \" + MPM[\"Model\"].str.replace(\"_\",\" \")\n",
    "            MPM = MPM.rename(columns={\"Model\":\"Product\",\"Mapping\":\"TimeDefinition\",\"Date\":\"Period\"})\n",
    "            MPM[\"Model Name\"] = MPM[\"Product\"] \n",
    "            MPM[\"Geography\"] = \"All\"\n",
    "            MPM[\"Channel\"] = \"All\"\n",
    "\n",
    "            Proper_Order = [\"Model Name\",\"Product\",\"Geography\",\"Channel\",\"TimeDefinition\",\"Period\"]\n",
    "            MPM = MPM[Proper_Order]\n",
    "            pm_df = metric_df.loc[\n",
    "\n",
    "\n",
    "            # MAKE CHANGES HERE    \n",
    "            metric_df[\"Metric\"].isin([\"PRICE\", \"MARGIN\"]),[\"Metric\", \"ModelKey\", \"CY 52\", \"LY52\", \"TYA52\"]].copy()\n",
    "            pm_long = pm_df.melt(id_vars=[\"Metric\", \"ModelKey\"],var_name=\"Mapping\",value_name=\"Value\")\n",
    "            pm_long = pm_long.merge(Time_Mapping,on=\"Mapping\",how=\"left\")\n",
    "            pm_long[\"Model Name\"] = (\"Cholula \" + pm_long[\"ModelKey\"].str.replace(\"_\", \" \", regex=False))\n",
    "            \n",
    "            pm_pivot = (pm_long.pivot(index=[\"Model Name\", \"Date\"],columns=\"Metric\",values=\"Value\").reset_index())\n",
    "            MPM = MPM.merge(pm_pivot,left_on=[\"Model Name\", \"Period\"],right_on=[\"Model Name\", \"Date\"],how=\"left\")\n",
    "            MPM[\"Price\"] = MPM[\"PRICE\"]\n",
    "            MPM[\"Margin\"] = MPM[\"MARGIN\"]\n",
    "\n",
    "            MPM.drop(columns=[\"PRICE\", \"MARGIN\", \"Date\"], inplace=True)\n",
    "            MPM.to_excel(writer,sheet_name=\"ModelPriceMargin\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ede72361-01d7-48dd-aa14-2e240f71fff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DONE\n",
      "Total Execution time: 28.93 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"ALL DONE\") \n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time \n",
    "print(f\"Total Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08856fe-dc84-4bed-8a59-42f5ec73d950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
